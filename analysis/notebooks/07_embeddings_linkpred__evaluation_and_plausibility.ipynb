{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc62922b",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Discover Embeddings/LinkPred Artifacts](#discover)\n",
    "3. [Load and Inspect Metrics](#load-metrics)\n",
    "4. [Embedding Quality Analysis](#embedding-quality)\n",
    "5. [Top Predictions Analysis](#top-predictions)\n",
    "6. [Prediction Plausibility](#plausibility)\n",
    "7. [Interpretation](#interpretation)\n",
    "8. [Write Report Outputs](#write-outputs)\n",
    "9. [Reproducibility Notes](#reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff0176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP AND IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Project paths\n",
    "REPO_ROOT = Path.cwd().parent.parent\n",
    "RESULTS_DIR = REPO_ROOT / \"results\"\n",
    "ANALYSIS_DIR = RESULTS_DIR / \"analysis\"\n",
    "TABLES_DIR = RESULTS_DIR / \"tables\"\n",
    "TABLES_REPORT_DIR = RESULTS_DIR / \"tables\" / \"report\"\n",
    "FIGURES_REPORT_DIR = RESULTS_DIR / \"figures\" / \"report\"\n",
    "WARNINGS_LOG = TABLES_REPORT_DIR / \"_warnings.log\"\n",
    "\n",
    "# Notebook identity\n",
    "NOTEBOOK_ID = \"nb07\"\n",
    "NOTEBOOK_NAME = \"embeddings_linkpred__evaluation_and_plausibility\"\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "TABLES_REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Analysis dir exists: {ANALYSIS_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c799fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def append_warning(message: str, notebook_id: str = NOTEBOOK_ID):\n",
    "    \"\"\"Append a warning to the consolidated warnings log.\"\"\"\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    with open(WARNINGS_LOG, \"a\") as f:\n",
    "        f.write(f\"[{timestamp}] [{notebook_id}] {message}\\n\")\n",
    "    print(f\"WARNING: {message}\")\n",
    "\n",
    "def safe_load_parquet(path: Path) -> pl.DataFrame | None:\n",
    "    \"\"\"Safely load a parquet file, returning None if it fails.\"\"\"\n",
    "    try:\n",
    "        return pl.read_parquet(path)\n",
    "    except Exception as e:\n",
    "        append_warning(f\"Failed to load {path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def flatten_metrics(metrics_dict: dict, prefix: str = \"\") -> dict:\n",
    "    \"\"\"Flatten nested metrics dictionary.\"\"\"\n",
    "    flat = {}\n",
    "    for k, v in metrics_dict.items():\n",
    "        key = f\"{prefix}{k}\" if prefix else k\n",
    "        if isinstance(v, dict):\n",
    "            flat.update(flatten_metrics(v, f\"{key}__\"))\n",
    "        else:\n",
    "            flat[key] = v\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce703be",
   "metadata": {},
   "source": [
    "<a id=\"discover\"></a>\n",
    "## 2. Discover Embeddings/LinkPred Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4decd6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DISCOVER ARTIFACTS\n",
    "# ============================================================================\n",
    "\n",
    "embed_keywords = [\"embed\", \"node2vec\", \"linkpred\", \"auc\", \"ap\", \"mrr\", \"hits\", \"prediction\"]\n",
    "\n",
    "# Search in analysis directory\n",
    "analysis_files = list(ANALYSIS_DIR.glob(\"*.parquet\")) + list(ANALYSIS_DIR.glob(\"*.json\"))\n",
    "embed_candidates = [\n",
    "    f for f in analysis_files \n",
    "    if any(kw in f.name.lower() for kw in embed_keywords)\n",
    "]\n",
    "\n",
    "# Search in tables directory for predictions\n",
    "table_files = list(TABLES_DIR.glob(\"*linkpred*.csv\")) + list(TABLES_DIR.glob(\"*prediction*.csv\"))\n",
    "\n",
    "print(f\"Found {len(embed_candidates)} embedding/linkpred artifacts in analysis/:\")\n",
    "for ef in sorted(embed_candidates):\n",
    "    print(f\"  - {ef.name}\")\n",
    "\n",
    "print(f\"\\nFound {len(table_files)} prediction tables in tables/:\")\n",
    "for tf in sorted(table_files):\n",
    "    print(f\"  - {tf.name}\")\n",
    "\n",
    "# Primary files\n",
    "linkpred_metrics_file = ANALYSIS_DIR / \"linkpred_metrics.json\"\n",
    "embeddings_file = ANALYSIS_DIR / \"airport_embeddings.parquet\"\n",
    "predictions_file = TABLES_DIR / \"linkpred_top_predictions.csv\"\n",
    "\n",
    "print(f\"\\nLink pred metrics exists: {linkpred_metrics_file.exists()}\")\n",
    "print(f\"Embeddings exists: {embeddings_file.exists()}\")\n",
    "print(f\"Top predictions exists: {predictions_file.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d2c0a2",
   "metadata": {},
   "source": [
    "<a id=\"load-metrics\"></a>\n",
    "## 3. Load and Inspect Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2127c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD AND INSPECT METRICS\n",
    "# ============================================================================\n",
    "\n",
    "linkpred_metrics = None\n",
    "metrics_flat = {}\n",
    "\n",
    "if linkpred_metrics_file.exists():\n",
    "    with open(linkpred_metrics_file) as f:\n",
    "        linkpred_metrics = json.load(f)\n",
    "    \n",
    "    print(\"LINK PREDICTION METRICS:\")\n",
    "    print(json.dumps(linkpred_metrics, indent=2))\n",
    "    \n",
    "    # Flatten for table output\n",
    "    metrics_flat = flatten_metrics(linkpred_metrics)\n",
    "else:\n",
    "    append_warning(\"linkpred_metrics.json not found\")\n",
    "    print(\"Not available: link prediction metrics not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec67d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SUMMARIZE METRICS IN TABLE FORM\n",
    "# ============================================================================\n",
    "\n",
    "if len(metrics_flat) > 0:\n",
    "    # Create metrics table\n",
    "    metrics_df = pd.DataFrame([\n",
    "        {\"metric\": k, \"value\": v} for k, v in metrics_flat.items()\n",
    "        if isinstance(v, (int, float))\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nFLATTENED METRICS TABLE:\")\n",
    "    display(metrics_df)\n",
    "    \n",
    "    # Highlight key performance indicators\n",
    "    key_metrics = [\"auc\", \"ap\", \"average_precision\", \"roc_auc\", \"mrr\", \"hits@10\"]\n",
    "    key_rows = metrics_df[metrics_df[\"metric\"].str.lower().str.contains(\"|\".join(key_metrics))]\n",
    "    \n",
    "    if len(key_rows) > 0:\n",
    "        print(\"\\nüìä KEY PERFORMANCE METRICS:\")\n",
    "        display(key_rows)\n",
    "else:\n",
    "    metrics_df = pd.DataFrame()\n",
    "    print(\"Not available: no metrics to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f3a0d",
   "metadata": {},
   "source": [
    "<a id=\"embedding-quality\"></a>\n",
    "## 4. Embedding Quality Analysis\n",
    "\n",
    "Perform basic sanity checks on embeddings if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0557b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EMBEDDING QUALITY ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "embeddings = None\n",
    "\n",
    "if embeddings_file.exists():\n",
    "    embeddings = safe_load_parquet(embeddings_file)\n",
    "    \n",
    "    if embeddings is not None:\n",
    "        print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "        print(f\"Columns: {embeddings.columns}\")\n",
    "        \n",
    "        # Identify embedding dimension columns (usually numeric, many columns)\n",
    "        numeric_cols = [c for c in embeddings.columns \n",
    "                       if embeddings[c].dtype in [pl.Float64, pl.Float32]]\n",
    "        \n",
    "        if len(numeric_cols) > 5:  # Likely embedding dimensions\n",
    "            print(f\"\\nDetected {len(numeric_cols)} embedding dimensions\")\n",
    "            \n",
    "            # Compute L2 norms\n",
    "            embed_matrix = embeddings.select(numeric_cols).to_numpy()\n",
    "            norms = np.linalg.norm(embed_matrix, axis=1)\n",
    "            \n",
    "            print(f\"\\nEmbedding Norm Statistics:\")\n",
    "            print(f\"  Mean: {norms.mean():.4f}\")\n",
    "            print(f\"  Std: {norms.std():.4f}\")\n",
    "            print(f\"  Min: {norms.min():.4f}\")\n",
    "            print(f\"  Max: {norms.max():.4f}\")\n",
    "            \n",
    "            # Check for degenerate embeddings\n",
    "            zero_norms = (norms < 1e-6).sum()\n",
    "            if zero_norms > 0:\n",
    "                append_warning(f\"{zero_norms} embeddings have near-zero norm\")\n",
    "            \n",
    "            # Plot norm distribution\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "            ax.hist(norms, bins=50, edgecolor=\"white\", alpha=0.8)\n",
    "            ax.set_xlabel(\"Embedding L2 Norm\")\n",
    "            ax.set_ylabel(\"Frequency\")\n",
    "            ax.set_title(f\"Embedding Norm Distribution (dim={len(numeric_cols)})\")\n",
    "            ax.axvline(norms.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean: {norms.mean():.3f}\")\n",
    "            ax.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            fig_path = FIGURES_REPORT_DIR / f\"{NOTEBOOK_ID}_embedding_norms_distribution.png\"\n",
    "            plt.savefig(fig_path, dpi=150)\n",
    "            plt.show()\n",
    "            print(f\"‚úÖ Saved: {fig_path.name}\")\n",
    "        else:\n",
    "            print(\"Could not identify embedding dimensions\")\n",
    "else:\n",
    "    print(\"Not available: embeddings file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f550c",
   "metadata": {},
   "source": [
    "<a id=\"top-predictions\"></a>\n",
    "## 5. Top Predictions Analysis\n",
    "\n",
    "Examine the top predicted new links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TOP PREDICTIONS ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "predictions = None\n",
    "\n",
    "if predictions_file.exists():\n",
    "    predictions = pd.read_csv(predictions_file)\n",
    "    print(f\"Top predictions shape: {predictions.shape}\")\n",
    "    print(f\"Columns: {list(predictions.columns)}\")\n",
    "    display(predictions.head(20))\n",
    "else:\n",
    "    print(\"Not available: top predictions file not found\")\n",
    "    \n",
    "    # Try alternative locations\n",
    "    for alt_file in TABLES_DIR.glob(\"*predict*.csv\"):\n",
    "        print(f\"Found alternative: {alt_file.name}\")\n",
    "        predictions = pd.read_csv(alt_file)\n",
    "        display(predictions.head(10))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e7abe",
   "metadata": {},
   "source": [
    "<a id=\"plausibility\"></a>\n",
    "## 6. Prediction Plausibility\n",
    "\n",
    "Assess whether predicted links are plausible based on network structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PREDICTION PLAUSIBILITY ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "if predictions is not None and len(predictions) > 0:\n",
    "    # Identify source/target columns\n",
    "    src_col = next((c for c in [\"source\", \"origin\", \"airport_1\", \"src\"] if c in predictions.columns), None)\n",
    "    dst_col = next((c for c in [\"target\", \"dest\", \"airport_2\", \"dst\"] if c in predictions.columns), None)\n",
    "    score_col = next((c for c in [\"score\", \"probability\", \"pred_score\", \"link_prob\"] if c in predictions.columns), None)\n",
    "    \n",
    "    if src_col and dst_col:\n",
    "        print(f\"\\nPrediction columns: source={src_col}, target={dst_col}, score={score_col}\")\n",
    "        \n",
    "        # Check if predictions cluster around mega-hubs\n",
    "        top_sources = predictions[src_col].value_counts().head(10)\n",
    "        top_targets = predictions[dst_col].value_counts().head(10)\n",
    "        \n",
    "        print(\"\\nMost frequent SOURCE airports in predictions:\")\n",
    "        print(top_sources)\n",
    "        \n",
    "        print(\"\\nMost frequent TARGET airports in predictions:\")\n",
    "        print(top_targets)\n",
    "        \n",
    "        # Plausibility assessment\n",
    "        mega_hubs = {\"ATL\", \"ORD\", \"DFW\", \"DEN\", \"LAX\", \"CLT\", \"PHX\", \"IAH\", \"SFO\", \"EWR\"}\n",
    "        hub_predictions = predictions[\n",
    "            predictions[src_col].isin(mega_hubs) | predictions[dst_col].isin(mega_hubs)\n",
    "        ]\n",
    "        hub_rate = len(hub_predictions) / len(predictions) if len(predictions) > 0 else 0\n",
    "        \n",
    "        print(f\"\\nüìä PLAUSIBILITY CHECK:\")\n",
    "        print(f\"   Predictions involving mega-hubs: {len(hub_predictions)} ({hub_rate:.1%})\")\n",
    "        if hub_rate > 0.5:\n",
    "            print(\"   ‚ö†Ô∏è High hub concentration suggests predictions may be trivial\")\n",
    "        else:\n",
    "            print(\"   ‚úÖ Predictions show structural diversity\")\n",
    "    else:\n",
    "        append_warning(f\"Could not identify source/target columns in predictions\")\n",
    "else:\n",
    "    print(\"Not available: no predictions to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1792376a",
   "metadata": {},
   "source": [
    "<a id=\"interpretation\"></a>\n",
    "## 7. Interpretation\n",
    "\n",
    "### Key Findings (Evidence-Grounded)\n",
    "\n",
    "*(Populated after running cells above)*\n",
    "\n",
    "### Mechanistic Explanation\n",
    "\n",
    "- **Node embeddings**: Capture structural similarity through random walk or matrix factorization\n",
    "- **Link prediction**: Dot product of embeddings estimates link probability\n",
    "- **AUC/AP metrics**: Measure ranking quality for positive vs negative edges\n",
    "\n",
    "### Evaluation Caveats\n",
    "1. **Time split leakage**: If test edges overlap temporally with training, performance is inflated\n",
    "2. **Class imbalance**: Link prediction has extreme negative/positive imbalance\n",
    "3. **Trivial predictions**: High-degree nodes are easy targets\n",
    "\n",
    "### Evidence Links\n",
    "- Table: `results/tables/report/nb07_linkpred_metrics_flat.csv`\n",
    "- Figure: `results/figures/report/nb07_embedding_norms_distribution.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375982f1",
   "metadata": {},
   "source": [
    "<a id=\"write-outputs\"></a>\n",
    "## 8. Write Report Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# WRITE REPORT OUTPUTS\n",
    "# ============================================================================\n",
    "\n",
    "# Write flattened metrics\n",
    "if len(metrics_df) > 0:\n",
    "    metrics_path = TABLES_REPORT_DIR / f\"{NOTEBOOK_ID}_linkpred_metrics_flat.csv\"\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "    print(f\"‚úÖ Wrote: {metrics_path}\")\n",
    "\n",
    "# Write annotated predictions\n",
    "if predictions is not None and len(predictions) > 0:\n",
    "    pred_path = TABLES_REPORT_DIR / f\"{NOTEBOOK_ID}_top_predictions_annotated.csv\"\n",
    "    predictions.to_csv(pred_path, index=False)\n",
    "    print(f\"‚úÖ Wrote: {pred_path}\")\n",
    "\n",
    "print(f\"\\nüìã All {NOTEBOOK_ID} outputs written.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c23969",
   "metadata": {},
   "source": [
    "<a id=\"reproducibility\"></a>\n",
    "## 9. Reproducibility Notes\n",
    "\n",
    "### Input Files Consumed\n",
    "- `results/analysis/linkpred_metrics.json`\n",
    "- `results/analysis/airport_embeddings.parquet`\n",
    "- `results/tables/linkpred_top_predictions.csv`\n",
    "\n",
    "### Assumptions Made\n",
    "1. Embeddings trained with node2vec or similar random walk method\n",
    "2. Link prediction uses temporal train/test split\n",
    "3. Metrics computed on hold-out edge set\n",
    "\n",
    "### Outputs Generated\n",
    "| Artifact | Path |\n",
    "|----------|------|\n",
    "| Metrics Table | `results/tables/report/nb07_linkpred_metrics_flat.csv` |\n",
    "| Embedding Norms | `results/figures/report/nb07_embedding_norms_distribution.png` |\n",
    "| Annotated Predictions | `results/tables/report/nb07_top_predictions_annotated.csv` |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
