{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "193dfb7b",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Discover Centrality Artifacts](#discover)\n",
    "3. [Load and Inspect Centrality Data](#load)\n",
    "4. [Top-K Rankings by Metric](#top-k)\n",
    "5. [Centrality Distributions](#distributions)\n",
    "6. [Connector vs Hub Analysis](#connector-hub)\n",
    "7. [Interpretation](#interpretation)\n",
    "8. [Write Report Outputs](#write-outputs)\n",
    "9. [Reproducibility Notes](#reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP AND IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Project paths\n",
    "REPO_ROOT = Path.cwd().parent.parent\n",
    "RESULTS_DIR = REPO_ROOT / \"results\"\n",
    "ANALYSIS_DIR = RESULTS_DIR / \"analysis\"\n",
    "TABLES_REPORT_DIR = RESULTS_DIR / \"tables\" / \"report\"\n",
    "FIGURES_REPORT_DIR = RESULTS_DIR / \"figures\" / \"report\"\n",
    "WARNINGS_LOG = TABLES_REPORT_DIR / \"_warnings.log\"\n",
    "\n",
    "# Notebook identity\n",
    "NOTEBOOK_ID = \"nb03\"\n",
    "NOTEBOOK_NAME = \"centrality__rankings_and_mechanisms\"\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "TABLES_REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Analysis dir exists: {ANALYSIS_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e3d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def append_warning(message: str, notebook_id: str = NOTEBOOK_ID):\n",
    "    \"\"\"Append a warning to the consolidated warnings log.\"\"\"\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    with open(WARNINGS_LOG, \"a\") as f:\n",
    "        f.write(f\"[{timestamp}] [{notebook_id}] {message}\\n\")\n",
    "    print(f\"WARNING: {message}\")\n",
    "\n",
    "def safe_load_parquet(path: Path) -> pl.DataFrame | None:\n",
    "    \"\"\"Safely load a parquet file, returning None if it fails.\"\"\"\n",
    "    try:\n",
    "        return pl.read_parquet(path)\n",
    "    except Exception as e:\n",
    "        append_warning(f\"Failed to load {path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_top_k(df: pl.DataFrame, metric_col: str, id_col: str, k: int = 20) -> pd.DataFrame:\n",
    "    \"\"\"Get top-k entries by a metric with stable tie-breaking.\"\"\"\n",
    "    return (\n",
    "        df\n",
    "        .sort([metric_col, id_col], descending=[True, False])  # Tie-break by ID ascending\n",
    "        .head(k)\n",
    "        .with_row_index(\"rank\", offset=1)\n",
    "        .to_pandas()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d67cb",
   "metadata": {},
   "source": [
    "<a id=\"discover\"></a>\n",
    "## 2. Discover Centrality Artifacts\n",
    "\n",
    "Search for files containing centrality-related keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e110cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DISCOVER CENTRALITY ARTIFACTS\n",
    "# ============================================================================\n",
    "\n",
    "centrality_keywords = [\"centrality\", \"pagerank\", \"betweenness\", \"closeness\", \"eigen\", \"degree\"]\n",
    "\n",
    "# Search in analysis directory\n",
    "analysis_files = list(ANALYSIS_DIR.glob(\"*.parquet\")) + list(ANALYSIS_DIR.glob(\"*.csv\"))\n",
    "centrality_candidates = [\n",
    "    f for f in analysis_files \n",
    "    if any(kw in f.name.lower() for kw in centrality_keywords)\n",
    "]\n",
    "\n",
    "print(f\"Found {len(centrality_candidates)} centrality-related artifacts:\")\n",
    "for cf in centrality_candidates:\n",
    "    print(f\"  - {cf.name}\")\n",
    "\n",
    "# Select primary centrality file\n",
    "primary_centrality_file = None\n",
    "for candidate in [\"airport_centrality.parquet\", \"centrality.parquet\"]:\n",
    "    path = ANALYSIS_DIR / candidate\n",
    "    if path.exists():\n",
    "        primary_centrality_file = path\n",
    "        break\n",
    "\n",
    "if primary_centrality_file:\n",
    "    print(f\"\\nâœ… Primary centrality file: {primary_centrality_file.name}\")\n",
    "else:\n",
    "    append_warning(\"No primary centrality file found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cf6ce9",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## 3. Load and Inspect Centrality Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD AND INSPECT CENTRALITY DATA\n",
    "# ============================================================================\n",
    "\n",
    "centrality_df = None\n",
    "if primary_centrality_file:\n",
    "    centrality_df = safe_load_parquet(primary_centrality_file)\n",
    "\n",
    "if centrality_df is not None:\n",
    "    print(f\"Centrality data shape: {centrality_df.shape}\")\n",
    "    print(f\"Columns: {centrality_df.columns}\")\n",
    "    display(centrality_df.head(10).to_pandas())\n",
    "    \n",
    "    # Identify node ID column\n",
    "    id_col = next((c for c in [\"airport\", \"node\", \"ORIGIN\", \"id\", \"name\"] if c in centrality_df.columns), None)\n",
    "    print(f\"\\nNode ID column: {id_col}\")\n",
    "    \n",
    "    # Identify numeric metric columns\n",
    "    numeric_cols = [c for c in centrality_df.columns if centrality_df[c].dtype in [pl.Float64, pl.Float32, pl.Int64, pl.Int32]]\n",
    "    metric_cols = [c for c in numeric_cols if c != id_col and not c.startswith(\"_\")]\n",
    "    print(f\"Metric columns: {metric_cols}\")\n",
    "else:\n",
    "    print(\"Not available: centrality data could not be loaded\")\n",
    "    id_col = None\n",
    "    metric_cols = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2388b3a",
   "metadata": {},
   "source": [
    "<a id=\"top-k\"></a>\n",
    "## 4. Top-K Rankings by Metric\n",
    "\n",
    "Compute top-20 rankings for each centrality metric with stable tie-breaking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8c2512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TOP-K RANKINGS BY METRIC\n",
    "# ============================================================================\n",
    "\n",
    "top_k_results = {}\n",
    "K = 20\n",
    "\n",
    "if centrality_df is not None and id_col and len(metric_cols) > 0:\n",
    "    for metric in metric_cols:\n",
    "        top_k = get_top_k(centrality_df, metric, id_col, K)\n",
    "        top_k_results[metric] = top_k\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"TOP {K} BY {metric.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        display(top_k[[\"rank\", id_col, metric]].head(10))\n",
    "else:\n",
    "    print(\"Not available: cannot compute top-k rankings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2268fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PLOT TOP-K BAR CHARTS\n",
    "# ============================================================================\n",
    "\n",
    "if len(top_k_results) > 0:\n",
    "    for metric, top_k in top_k_results.items():\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        colors = sns.color_palette(\"viridis\", len(top_k))\n",
    "        bars = ax.barh(range(len(top_k)), top_k[metric], color=colors)\n",
    "        ax.set_yticks(range(len(top_k)))\n",
    "        ax.set_yticklabels(top_k[id_col])\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel(metric.replace(\"_\", \" \").title())\n",
    "        ax.set_title(f\"Top {K} Airports by {metric.replace('_', ' ').title()}\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        fig_path = FIGURES_REPORT_DIR / f\"{NOTEBOOK_ID}_centrality_top20__{metric}.png\"\n",
    "        plt.savefig(fig_path, dpi=150)\n",
    "        plt.show()\n",
    "        print(f\"âœ… Saved: {fig_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af73c3a6",
   "metadata": {},
   "source": [
    "<a id=\"distributions\"></a>\n",
    "## 5. Centrality Distributions\n",
    "\n",
    "Visualize the distribution of centrality metrics to identify concentration patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CENTRALITY DISTRIBUTIONS\n",
    "# ============================================================================\n",
    "\n",
    "if centrality_df is not None and len(metric_cols) > 0:\n",
    "    n_metrics = len(metric_cols)\n",
    "    n_cols = min(3, n_metrics)\n",
    "    n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))\n",
    "    axes = np.atleast_2d(axes).flatten()\n",
    "    \n",
    "    for i, metric in enumerate(metric_cols):\n",
    "        ax = axes[i]\n",
    "        values = centrality_df[metric].to_numpy()\n",
    "        \n",
    "        # Use log scale if values span multiple orders of magnitude\n",
    "        use_log = (values.max() / (values.min() + 1e-10)) > 100\n",
    "        \n",
    "        ax.hist(values, bins=50, edgecolor=\"white\", alpha=0.8, log=use_log)\n",
    "        ax.set_xlabel(metric.replace(\"_\", \" \").title())\n",
    "        ax.set_ylabel(\"Frequency\" + (\" (log)\" if use_log else \"\"))\n",
    "        ax.set_title(f\"{metric} Distribution\")\n",
    "        \n",
    "        # Add mean line\n",
    "        ax.axvline(values.mean(), color=\"red\", linestyle=\"--\", alpha=0.7, label=f\"Mean: {values.mean():.2e}\")\n",
    "        ax.legend(fontsize=8)\n",
    "    \n",
    "    # Hide unused axes\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig_path = FIGURES_REPORT_DIR / f\"{NOTEBOOK_ID}_centrality_distributions.png\"\n",
    "    plt.savefig(fig_path, dpi=150)\n",
    "    plt.show()\n",
    "    print(f\"âœ… Saved: {fig_path.name}\")\n",
    "else:\n",
    "    print(\"Not available: cannot plot distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2591b2",
   "metadata": {},
   "source": [
    "<a id=\"connector-hub\"></a>\n",
    "## 6. Connector vs Hub Analysis\n",
    "\n",
    "Identify airports that are high-betweenness but not top-degree (connectors/bridges)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59ba3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONNECTOR VS HUB ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "if centrality_df is not None:\n",
    "    # Look for betweenness and degree columns\n",
    "    betweenness_col = next((c for c in metric_cols if \"betweenness\" in c.lower()), None)\n",
    "    degree_col = next((c for c in metric_cols if \"degree\" in c.lower() or \"strength\" in c.lower()), None)\n",
    "    \n",
    "    if betweenness_col and degree_col:\n",
    "        print(f\"Comparing {betweenness_col} vs {degree_col}\")\n",
    "        \n",
    "        # Compute percentile ranks\n",
    "        df_analysis = centrality_df.to_pandas()\n",
    "        df_analysis[\"betweenness_pctile\"] = df_analysis[betweenness_col].rank(pct=True)\n",
    "        df_analysis[\"degree_pctile\"] = df_analysis[degree_col].rank(pct=True)\n",
    "        \n",
    "        # Identify connectors: high betweenness (>90th) but lower degree (<75th)\n",
    "        connectors = df_analysis[\n",
    "            (df_analysis[\"betweenness_pctile\"] > 0.90) & \n",
    "            (df_analysis[\"degree_pctile\"] < 0.75)\n",
    "        ].sort_values(betweenness_col, ascending=False)\n",
    "        \n",
    "        print(f\"\\nðŸ”— POTENTIAL CONNECTORS (high betweenness, moderate degree): {len(connectors)}\")\n",
    "        if len(connectors) > 0:\n",
    "            display(connectors[[id_col, betweenness_col, degree_col, \"betweenness_pctile\", \"degree_pctile\"]].head(10))\n",
    "        \n",
    "        # Identify mega-hubs: high on both\n",
    "        mega_hubs = df_analysis[\n",
    "            (df_analysis[\"betweenness_pctile\"] > 0.95) & \n",
    "            (df_analysis[\"degree_pctile\"] > 0.95)\n",
    "        ].sort_values(degree_col, ascending=False)\n",
    "        \n",
    "        print(f\"\\nðŸ¢ MEGA-HUBS (high on both): {len(mega_hubs)}\")\n",
    "        if len(mega_hubs) > 0:\n",
    "            display(mega_hubs[[id_col, betweenness_col, degree_col]].head(10))\n",
    "    else:\n",
    "        print(f\"Not available: could not find betweenness ({betweenness_col}) or degree ({degree_col}) columns\")\n",
    "else:\n",
    "    print(\"Not available: centrality data not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3966f24c",
   "metadata": {},
   "source": [
    "<a id=\"interpretation\"></a>\n",
    "## 7. Interpretation\n",
    "\n",
    "### Key Findings (Evidence-Grounded)\n",
    "\n",
    "*(Populated after running cells above)*\n",
    "\n",
    "### Mechanistic Explanation\n",
    "\n",
    "- **Betweenness centrality**: Measures bridging/brokerage roles - airports on many shortest paths\n",
    "- **PageRank/Eigenvector**: Measures global influence - connected to well-connected airports\n",
    "- **Degree/Strength**: Measures local connectivity - number/volume of direct connections\n",
    "\n",
    "### Alternative Explanations\n",
    "1. Geographic positioning may drive betweenness (central US locations)\n",
    "2. Airline hub strategy decisions may drive degree concentration\n",
    "\n",
    "### Evidence Links\n",
    "- Table: `results/tables/report/nb03_centrality_top20_by_metric.csv`\n",
    "- Figures: `results/figures/report/nb03_centrality_top20__*.png`\n",
    "- Figure: `results/figures/report/nb03_centrality_distributions.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39507e90",
   "metadata": {},
   "source": [
    "<a id=\"write-outputs\"></a>\n",
    "## 8. Write Report Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83261896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# WRITE REPORT OUTPUTS\n",
    "# ============================================================================\n",
    "\n",
    "# Combine all top-k results into a single table\n",
    "if len(top_k_results) > 0:\n",
    "    combined_rows = []\n",
    "    for metric, top_k in top_k_results.items():\n",
    "        for _, row in top_k.iterrows():\n",
    "            combined_rows.append({\n",
    "                \"metric\": metric,\n",
    "                \"rank\": row[\"rank\"],\n",
    "                \"airport\": row[id_col],\n",
    "                \"value\": row[metric]\n",
    "            })\n",
    "    \n",
    "    combined_df = pd.DataFrame(combined_rows)\n",
    "    combined_path = TABLES_REPORT_DIR / f\"{NOTEBOOK_ID}_centrality_top20_by_metric.csv\"\n",
    "    combined_df.to_csv(combined_path, index=False)\n",
    "    print(f\"âœ… Wrote: {combined_path}\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ All {NOTEBOOK_ID} outputs written.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6f8e2",
   "metadata": {},
   "source": [
    "<a id=\"reproducibility\"></a>\n",
    "## 9. Reproducibility Notes\n",
    "\n",
    "### Input Files Consumed\n",
    "- `results/analysis/airport_centrality.parquet`\n",
    "\n",
    "### Assumptions Made\n",
    "1. Centrality metrics were computed on the directed weighted airport network\n",
    "2. Betweenness is normalized by the number of node pairs\n",
    "3. PageRank uses default damping factor (typically 0.85)\n",
    "\n",
    "### Sorting/Ordering\n",
    "- Tie-breaking: by airport code ascending when metrics are equal\n",
    "- All rankings are stable and deterministic\n",
    "\n",
    "### Caveats\n",
    "- Centrality semantics depend on network construction choices (directed vs undirected, weighted vs unweighted)\n",
    "- Results may differ if computed on largest connected component only\n",
    "\n",
    "### Outputs Generated\n",
    "| Artifact | Path |\n",
    "|----------|------|\n",
    "| Combined Rankings | `results/tables/report/nb03_centrality_top20_by_metric.csv` |\n",
    "| Top-K Figures | `results/figures/report/nb03_centrality_top20__*.png` |\n",
    "| Distributions | `results/figures/report/nb03_centrality_distributions.png` |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
