{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc5da3c6",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Discover Delay Propagation Artifacts](#discover)\n",
    "3. [Load and Inspect Delay Data](#load)\n",
    "4. [Cascade Size Distribution](#cascade-dist)\n",
    "5. [Superspreader Ranking](#superspreaders)\n",
    "6. [Centrality Overlap Analysis](#overlap)\n",
    "7. [Interpretation](#interpretation)\n",
    "8. [Write Report Outputs](#write-outputs)\n",
    "9. [Reproducibility Notes](#reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00eac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP AND IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Project paths\n",
    "REPO_ROOT = Path.cwd().parent.parent\n",
    "RESULTS_DIR = REPO_ROOT / \"results\"\n",
    "ANALYSIS_DIR = RESULTS_DIR / \"analysis\"\n",
    "TABLES_REPORT_DIR = RESULTS_DIR / \"tables\" / \"report\"\n",
    "FIGURES_REPORT_DIR = RESULTS_DIR / \"figures\" / \"report\"\n",
    "WARNINGS_LOG = TABLES_REPORT_DIR / \"_warnings.log\"\n",
    "\n",
    "# Notebook identity\n",
    "NOTEBOOK_ID = \"nb06\"\n",
    "NOTEBOOK_NAME = \"delay_propagation__cascades_and_superspreaders\"\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "TABLES_REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Analysis dir exists: {ANALYSIS_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bacc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def append_warning(message: str, notebook_id: str = NOTEBOOK_ID):\n",
    "    \"\"\"Append a warning to the consolidated warnings log.\"\"\"\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    with open(WARNINGS_LOG, \"a\") as f:\n",
    "        f.write(f\"[{timestamp}] [{notebook_id}] {message}\\n\")\n",
    "    print(f\"WARNING: {message}\")\n",
    "\n",
    "def safe_load_parquet(path: Path) -> pl.DataFrame | None:\n",
    "    \"\"\"Safely load a parquet file, returning None if it fails.\"\"\"\n",
    "    try:\n",
    "        return pl.read_parquet(path)\n",
    "    except Exception as e:\n",
    "        append_warning(f\"Failed to load {path.name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f534d",
   "metadata": {},
   "source": [
    "<a id=\"discover\"></a>\n",
    "## 2. Discover Delay Propagation Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c975ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DISCOVER DELAY PROPAGATION ARTIFACTS\n",
    "# ============================================================================\n",
    "\n",
    "delay_keywords = [\"delay\", \"propagation\", \"cascade\", \"spread\", \"superspreader\", \"contagion\"]\n",
    "\n",
    "# Search in analysis directory\n",
    "analysis_files = list(ANALYSIS_DIR.glob(\"*.parquet\")) + list(ANALYSIS_DIR.glob(\"*.csv\")) + list(ANALYSIS_DIR.glob(\"*.json\"))\n",
    "delay_candidates = [\n",
    "    f for f in analysis_files \n",
    "    if any(kw in f.name.lower() for kw in delay_keywords)\n",
    "]\n",
    "\n",
    "print(f\"Found {len(delay_candidates)} delay propagation artifacts:\")\n",
    "for df in sorted(delay_candidates):\n",
    "    print(f\"  - {df.name}\")\n",
    "\n",
    "# Primary files\n",
    "delay_cascades_file = ANALYSIS_DIR / \"delay_cascades.parquet\"\n",
    "delay_summary_file = ANALYSIS_DIR / \"delay_propagation_summary.json\"\n",
    "\n",
    "print(f\"\\nDelay cascades exists: {delay_cascades_file.exists()}\")\n",
    "print(f\"Delay summary exists: {delay_summary_file.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e24607",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## 3. Load and Inspect Delay Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e91ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD AND INSPECT DELAY DATA\n",
    "# ============================================================================\n",
    "\n",
    "delay_cascades = None\n",
    "delay_summary = None\n",
    "\n",
    "# Load cascades\n",
    "if delay_cascades_file.exists():\n",
    "    delay_cascades = safe_load_parquet(delay_cascades_file)\n",
    "    if delay_cascades is not None:\n",
    "        print(f\"Delay cascades shape: {delay_cascades.shape}\")\n",
    "        print(f\"Columns: {delay_cascades.columns}\")\n",
    "        display(delay_cascades.head(10).to_pandas())\n",
    "else:\n",
    "    append_warning(\"delay_cascades.parquet not found\")\n",
    "\n",
    "# Load summary\n",
    "if delay_summary_file.exists():\n",
    "    with open(delay_summary_file) as f:\n",
    "        delay_summary = json.load(f)\n",
    "    print(f\"\\nDelay summary:\")\n",
    "    for k, v in delay_summary.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "else:\n",
    "    print(\"\\nDelay summary not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6d1f7",
   "metadata": {},
   "source": [
    "<a id=\"cascade-dist\"></a>\n",
    "## 4. Cascade Size Distribution\n",
    "\n",
    "Analyze the distribution of cascade sizes to check for heavy tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41283dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CASCADE SIZE DISTRIBUTION\n",
    "# ============================================================================\n",
    "\n",
    "if delay_cascades is not None:\n",
    "    # Identify cascade size column\n",
    "    size_col = next((c for c in [\"cascade_size\", \"n_infected\", \"affected_flights\", \"size\", \"total_affected\"] \n",
    "                     if c in delay_cascades.columns), None)\n",
    "    \n",
    "    if size_col:\n",
    "        print(f\"Using cascade size column: {size_col}\")\n",
    "        \n",
    "        # Compute frequency distribution\n",
    "        cascade_sizes = delay_cascades[size_col].to_numpy()\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(f\"\\nCascade Size Statistics:\")\n",
    "        print(f\"  Count: {len(cascade_sizes)}\")\n",
    "        print(f\"  Min: {cascade_sizes.min()}\")\n",
    "        print(f\"  Max: {cascade_sizes.max()}\")\n",
    "        print(f\"  Mean: {cascade_sizes.mean():.2f}\")\n",
    "        print(f\"  Median: {np.median(cascade_sizes):.0f}\")\n",
    "        print(f\"  Std: {cascade_sizes.std():.2f}\")\n",
    "        \n",
    "        # 90th and 99th percentiles\n",
    "        p90 = np.percentile(cascade_sizes, 90)\n",
    "        p99 = np.percentile(cascade_sizes, 99)\n",
    "        print(f\"  90th percentile: {p90:.0f}\")\n",
    "        print(f\"  99th percentile: {p99:.0f}\")\n",
    "        \n",
    "        # Frequency table\n",
    "        cascade_freq = (\n",
    "            delay_cascades\n",
    "            .group_by(size_col)\n",
    "            .agg(pl.count().alias(\"frequency\"))\n",
    "            .sort(size_col)\n",
    "        )\n",
    "        \n",
    "        # Plot\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Histogram\n",
    "        ax1 = axes[0]\n",
    "        ax1.hist(cascade_sizes, bins=50, edgecolor=\"white\", alpha=0.8, log=True)\n",
    "        ax1.set_xlabel(\"Cascade Size\")\n",
    "        ax1.set_ylabel(\"Frequency (log scale)\")\n",
    "        ax1.set_title(\"Cascade Size Distribution\")\n",
    "        ax1.axvline(p90, color=\"orange\", linestyle=\"--\", label=f\"90th pctl: {p90:.0f}\")\n",
    "        ax1.axvline(p99, color=\"red\", linestyle=\"--\", label=f\"99th pctl: {p99:.0f}\")\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Log-log plot to check for power law\n",
    "        ax2 = axes[1]\n",
    "        freq_df = cascade_freq.to_pandas()\n",
    "        ax2.scatter(freq_df[size_col], freq_df[\"frequency\"], alpha=0.6, s=20)\n",
    "        ax2.set_xscale(\"log\")\n",
    "        ax2.set_yscale(\"log\")\n",
    "        ax2.set_xlabel(\"Cascade Size (log)\")\n",
    "        ax2.set_ylabel(\"Frequency (log)\")\n",
    "        ax2.set_title(\"Log-Log Plot (Heavy Tail Check)\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        fig_path = FIGURES_REPORT_DIR / f\"{NOTEBOOK_ID}_cascade_size_distribution.png\"\n",
    "        plt.savefig(fig_path, dpi=150)\n",
    "        plt.show()\n",
    "        print(f\"âœ… Saved: {fig_path.name}\")\n",
    "    else:\n",
    "        append_warning(\"Could not identify cascade size column\")\n",
    "else:\n",
    "    print(\"Not available: delay cascades data not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168806e3",
   "metadata": {},
   "source": [
    "<a id=\"superspreaders\"></a>\n",
    "## 5. Superspreader Ranking\n",
    "\n",
    "Identify nodes that generate the largest delay cascades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb536b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SUPERSPREADER RANKING\n",
    "# ============================================================================\n",
    "\n",
    "superspreaders = None\n",
    "\n",
    "if delay_cascades is not None:\n",
    "    # Identify node/source column\n",
    "    source_col = next((c for c in [\"seed_airport\", \"source\", \"origin\", \"seed_node\", \"airport\"] \n",
    "                       if c in delay_cascades.columns), None)\n",
    "    \n",
    "    # Identify impact column\n",
    "    impact_col = next((c for c in [\"total_delay_impact\", \"cascade_size\", \"total_affected\", \"impact\", \"n_infected\"] \n",
    "                       if c in delay_cascades.columns), None)\n",
    "    \n",
    "    if source_col and impact_col:\n",
    "        print(f\"Source column: {source_col}, Impact column: {impact_col}\")\n",
    "        \n",
    "        # Aggregate impact by source node\n",
    "        superspreaders = (\n",
    "            delay_cascades\n",
    "            .group_by(source_col)\n",
    "            .agg([\n",
    "                pl.col(impact_col).sum().alias(\"total_impact\"),\n",
    "                pl.col(impact_col).mean().alias(\"mean_impact\"),\n",
    "                pl.col(impact_col).max().alias(\"max_impact\"),\n",
    "                pl.count().alias(\"n_cascades\")\n",
    "            ])\n",
    "            .sort(\"total_impact\", descending=True)\n",
    "            .with_row_index(\"rank\", offset=1)\n",
    "            .head(20)\n",
    "        )\n",
    "        \n",
    "        print(\"\\nTOP 20 DELAY SUPERSPREADERS:\")\n",
    "        display(superspreaders.to_pandas())\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ss_df = superspreaders.to_pandas()\n",
    "        \n",
    "        colors = sns.color_palette(\"Reds_r\", len(ss_df))\n",
    "        bars = ax.barh(range(len(ss_df)), ss_df[\"total_impact\"], color=colors)\n",
    "        ax.set_yticks(range(len(ss_df)))\n",
    "        ax.set_yticklabels(ss_df[source_col])\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel(\"Total Delay Impact\")\n",
    "        ax.set_title(\"Top 20 Delay Superspreader Airports\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        fig_path = FIGURES_REPORT_DIR / f\"{NOTEBOOK_ID}_delay_superspreaders_top20.png\"\n",
    "        plt.savefig(fig_path, dpi=150)\n",
    "        plt.show()\n",
    "        print(f\"âœ… Saved: {fig_path.name}\")\n",
    "    else:\n",
    "        append_warning(f\"Could not identify source ({source_col}) or impact ({impact_col}) columns\")\n",
    "else:\n",
    "    print(\"Not available: delay cascades data not loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4a7f74",
   "metadata": {},
   "source": [
    "<a id=\"overlap\"></a>\n",
    "## 6. Centrality Overlap Analysis\n",
    "\n",
    "Compare superspreaders with structurally central airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36354b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CENTRALITY OVERLAP ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "overlap_df = None\n",
    "\n",
    "if superspreaders is not None:\n",
    "    # Load centrality data\n",
    "    centrality_file = ANALYSIS_DIR / \"airport_centrality.parquet\"\n",
    "    \n",
    "    if centrality_file.exists():\n",
    "        centrality = safe_load_parquet(centrality_file)\n",
    "        \n",
    "        if centrality is not None:\n",
    "            # Identify matching ID column\n",
    "            cent_id_col = next((c for c in [\"airport\", \"node\", \"id\"] if c in centrality.columns), None)\n",
    "            \n",
    "            if cent_id_col:\n",
    "                # Get top-20 by betweenness\n",
    "                betweenness_col = next((c for c in centrality.columns if \"betweenness\" in c.lower()), None)\n",
    "                \n",
    "                if betweenness_col:\n",
    "                    top_centrality = set(\n",
    "                        centrality.sort(betweenness_col, descending=True)\n",
    "                        .head(20)[cent_id_col]\n",
    "                        .to_list()\n",
    "                    )\n",
    "                    top_superspreaders = set(superspreaders[source_col].to_list())\n",
    "                    \n",
    "                    overlap = top_centrality & top_superspreaders\n",
    "                    overlap_rate = len(overlap) / 20\n",
    "                    \n",
    "                    print(f\"\\nðŸ“Š CENTRALITY-DELAY OVERLAP ANALYSIS:\")\n",
    "                    print(f\"   Top-20 by {betweenness_col}: {len(top_centrality)} airports\")\n",
    "                    print(f\"   Top-20 superspreaders: {len(top_superspreaders)} airports\")\n",
    "                    print(f\"   Overlap: {len(overlap)} airports ({overlap_rate:.1%})\")\n",
    "                    print(f\"   Overlapping airports: {sorted(overlap)}\")\n",
    "                    \n",
    "                    # Create overlap table\n",
    "                    overlap_data = []\n",
    "                    for airport in top_superspreaders:\n",
    "                        overlap_data.append({\n",
    "                            \"airport\": airport,\n",
    "                            \"in_top20_superspreaders\": True,\n",
    "                            \"in_top20_centrality\": airport in top_centrality\n",
    "                        })\n",
    "                    for airport in top_centrality - top_superspreaders:\n",
    "                        overlap_data.append({\n",
    "                            \"airport\": airport,\n",
    "                            \"in_top20_superspreaders\": False,\n",
    "                            \"in_top20_centrality\": True\n",
    "                        })\n",
    "                    overlap_df = pd.DataFrame(overlap_data)\n",
    "                else:\n",
    "                    append_warning(\"Betweenness column not found in centrality data\")\n",
    "            else:\n",
    "                append_warning(\"Could not identify ID column in centrality data\")\n",
    "    else:\n",
    "        print(\"Centrality data not found - overlap analysis not available\")\n",
    "else:\n",
    "    print(\"Not available: superspreaders not computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3695c419",
   "metadata": {},
   "source": [
    "<a id=\"interpretation\"></a>\n",
    "## 7. Interpretation\n",
    "\n",
    "### Key Findings (Evidence-Grounded)\n",
    "\n",
    "*(Populated after running cells above)*\n",
    "\n",
    "### Mechanistic Explanation\n",
    "\n",
    "- **Cascade dynamics**: Delays propagate through connecting flights, creating cascades\n",
    "- **Heavy tails**: Power-law-like distributions suggest rare but extreme disruption events\n",
    "- **Superspreaders as bridges**: High-betweenness nodes connect many paths, amplifying cascades\n",
    "\n",
    "### Alternative Explanations\n",
    "1. Weather events may cause correlated delays at geographic clusters\n",
    "2. Schedule banking at hubs creates synchronized vulnerability windows\n",
    "3. Capacity constraints at busy airports amplify initial delays\n",
    "\n",
    "### Evidence Links\n",
    "- Figure: `results/figures/report/nb06_cascade_size_distribution.png`\n",
    "- Table: `results/tables/report/nb06_delay_superspreaders_top20.csv`\n",
    "- Table: `results/tables/report/nb06_centrality_delay_overlap.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74497d20",
   "metadata": {},
   "source": [
    "<a id=\"write-outputs\"></a>\n",
    "## 8. Write Report Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# WRITE REPORT OUTPUTS\n",
    "# ============================================================================\n",
    "\n",
    "# Write cascade size distribution\n",
    "if delay_cascades is not None and size_col:\n",
    "    cascade_freq_path = TABLES_REPORT_DIR / f\"{NOTEBOOK_ID}_cascade_size_distribution.csv\"\n",
    "    cascade_freq.to_pandas().to_csv(cascade_freq_path, index=False)\n",
    "    print(f\"âœ… Wrote: {cascade_freq_path}\")\n",
    "\n",
    "# Write superspreaders\n",
    "if superspreaders is not None:\n",
    "    ss_path = TABLES_REPORT_DIR / f\"{NOTEBOOK_ID}_delay_superspreaders_top20.csv\"\n",
    "    superspreaders.to_pandas().to_csv(ss_path, index=False)\n",
    "    print(f\"âœ… Wrote: {ss_path}\")\n",
    "\n",
    "# Write overlap\n",
    "if overlap_df is not None:\n",
    "    overlap_path = TABLES_REPORT_DIR / f\"{NOTEBOOK_ID}_centrality_delay_overlap.csv\"\n",
    "    overlap_df.to_csv(overlap_path, index=False)\n",
    "    print(f\"âœ… Wrote: {overlap_path}\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ All {NOTEBOOK_ID} outputs written.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ddff6",
   "metadata": {},
   "source": [
    "<a id=\"reproducibility\"></a>\n",
    "## 9. Reproducibility Notes\n",
    "\n",
    "### Input Files Consumed\n",
    "- `results/analysis/delay_cascades.parquet`\n",
    "- `results/analysis/delay_propagation_summary.json`\n",
    "- `results/analysis/airport_centrality.parquet` (for overlap analysis)\n",
    "\n",
    "### Assumptions Made\n",
    "1. Cascade data comes from IC-model simulation or empirical delay tracking\n",
    "2. Impact metric represents total propagated delay\n",
    "3. Overlap analysis uses top-20 threshold for both rankings\n",
    "\n",
    "### Sorting/Ordering\n",
    "- Superspreaders ranked by total impact descending\n",
    "- Tie-breaking by airport code ascending\n",
    "\n",
    "### Outputs Generated\n",
    "| Artifact | Path |\n",
    "|----------|------|\n",
    "| Cascade Distribution | `results/tables/report/nb06_cascade_size_distribution.csv` |\n",
    "| Cascade Distribution Figure | `results/figures/report/nb06_cascade_size_distribution.png` |\n",
    "| Superspreaders Table | `results/tables/report/nb06_delay_superspreaders_top20.csv` |\n",
    "| Superspreaders Figure | `results/figures/report/nb06_delay_superspreaders_top20.png` |\n",
    "| Overlap Analysis | `results/tables/report/nb06_centrality_delay_overlap.csv` |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
