{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "464c1b3c",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Inventory Network Artifacts](#inventory)\n",
    "3. [Load and Inspect Network Tables](#load-inspect)\n",
    "4. [Top Routes Analysis](#top-routes)\n",
    "5. [Degree/Strength Distribution](#degree-dist)\n",
    "6. [Integrity Checks](#integrity)\n",
    "7. [Interpretation](#interpretation)\n",
    "8. [Write Report Outputs](#write-outputs)\n",
    "9. [Reproducibility Notes](#reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd81d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP AND IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Project paths\n",
    "REPO_ROOT = Path.cwd().parent.parent\n",
    "RESULTS_DIR = REPO_ROOT / \"results\"\n",
    "NETWORKS_DIR = RESULTS_DIR / \"networks\"\n",
    "TABLES_REPORT_DIR = RESULTS_DIR / \"tables\" / \"report\"\n",
    "FIGURES_REPORT_DIR = RESULTS_DIR / \"figures\" / \"report\"\n",
    "WARNINGS_LOG = TABLES_REPORT_DIR / \"_warnings.log\"\n",
    "\n",
    "# Notebook identity\n",
    "NOTEBOOK_ID = \"nb02\"\n",
    "NOTEBOOK_NAME = \"network_construction__structure_and_sanity\"\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "TABLES_REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Networks dir exists: {NETWORKS_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def append_warning(message: str, notebook_id: str = NOTEBOOK_ID):\n",
    "    \"\"\"Append a warning to the consolidated warnings log.\"\"\"\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    with open(WARNINGS_LOG, \"a\") as f:\n",
    "        f.write(f\"[{timestamp}] [{notebook_id}] {message}\\n\")\n",
    "    print(f\"WARNING: {message}\")\n",
    "\n",
    "def safe_load_parquet(path: Path) -> pl.DataFrame | None:\n",
    "    \"\"\"Safely load a parquet file, returning None if it fails.\"\"\"\n",
    "    try:\n",
    "        return pl.read_parquet(path)\n",
    "    except Exception as e:\n",
    "        append_warning(f\"Failed to load {path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def summarize_schema(df: pl.DataFrame, name: str) -> dict:\n",
    "    \"\"\"Summarize the schema and basic stats of a DataFrame.\"\"\"\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"n_rows\": len(df),\n",
    "        \"n_cols\": len(df.columns),\n",
    "        \"columns\": \", \".join(df.columns[:10]) + (\"...\" if len(df.columns) > 10 else \"\"),\n",
    "        \"memory_mb\": df.estimated_size(\"mb\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb693d1",
   "metadata": {},
   "source": [
    "<a id=\"inventory\"></a>\n",
    "## 2. Inventory Network Artifacts\n",
    "\n",
    "Scan `results/networks/` for all network-related files and summarize their schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INVENTORY NETWORK ARTIFACTS\n",
    "# ============================================================================\n",
    "\n",
    "network_files = list(NETWORKS_DIR.glob(\"*.parquet\")) + list(NETWORKS_DIR.glob(\"*.csv\"))\n",
    "print(f\"Found {len(network_files)} network artifacts:\")\n",
    "for nf in sorted(network_files):\n",
    "    print(f\"  - {nf.name} ({nf.stat().st_size / 1024:.1f} KB)\")\n",
    "\n",
    "# Load and summarize each\n",
    "network_summaries = []\n",
    "network_dfs = {}\n",
    "\n",
    "for nf in sorted(network_files):\n",
    "    if nf.suffix == \".parquet\":\n",
    "        df = safe_load_parquet(nf)\n",
    "        if df is not None:\n",
    "            network_dfs[nf.stem] = df\n",
    "            network_summaries.append(summarize_schema(df, nf.name))\n",
    "\n",
    "inventory_df = pd.DataFrame(network_summaries)\n",
    "print(\"\\nNetwork Artifact Inventory:\")\n",
    "display(inventory_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c3782d",
   "metadata": {},
   "source": [
    "<a id=\"load-inspect\"></a>\n",
    "## 3. Load and Inspect Network Tables\n",
    "\n",
    "Examine the structure of airport and flight network node/edge tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b7490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INSPECT AIRPORT NETWORK\n",
    "# ============================================================================\n",
    "\n",
    "# Airport nodes\n",
    "if \"airport_nodes\" in network_dfs:\n",
    "    airport_nodes = network_dfs[\"airport_nodes\"]\n",
    "    print(\"AIRPORT NODES:\")\n",
    "    print(f\"  Shape: {airport_nodes.shape}\")\n",
    "    print(f\"  Columns: {airport_nodes.columns}\")\n",
    "    display(airport_nodes.head(5).to_pandas())\n",
    "else:\n",
    "    append_warning(\"airport_nodes.parquet not found\")\n",
    "    airport_nodes = None\n",
    "\n",
    "# Airport edges\n",
    "if \"airport_edges\" in network_dfs:\n",
    "    airport_edges = network_dfs[\"airport_edges\"]\n",
    "    print(\"\\nAIRPORT EDGES:\")\n",
    "    print(f\"  Shape: {airport_edges.shape}\")\n",
    "    print(f\"  Columns: {airport_edges.columns}\")\n",
    "    display(airport_edges.head(5).to_pandas())\n",
    "else:\n",
    "    append_warning(\"airport_edges.parquet not found\")\n",
    "    airport_edges = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dacd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INSPECT FLIGHT NETWORK\n",
    "# ============================================================================\n",
    "\n",
    "# Flight nodes\n",
    "if \"flight_nodes\" in network_dfs:\n",
    "    flight_nodes = network_dfs[\"flight_nodes\"]\n",
    "    print(\"FLIGHT NODES:\")\n",
    "    print(f\"  Shape: {flight_nodes.shape}\")\n",
    "    print(f\"  Columns: {flight_nodes.columns}\")\n",
    "    display(flight_nodes.head(5).to_pandas())\n",
    "else:\n",
    "    append_warning(\"flight_nodes.parquet not found\")\n",
    "    flight_nodes = None\n",
    "\n",
    "# Flight edges\n",
    "if \"flight_edges\" in network_dfs:\n",
    "    flight_edges = network_dfs[\"flight_edges\"]\n",
    "    print(\"\\nFLIGHT EDGES:\")\n",
    "    print(f\"  Shape: {flight_edges.shape}\")\n",
    "    print(f\"  Columns: {flight_edges.columns}\")\n",
    "    display(flight_edges.head(5).to_pandas())\n",
    "else:\n",
    "    append_warning(\"flight_edges.parquet not found\")\n",
    "    flight_edges = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1253492",
   "metadata": {},
   "source": [
    "<a id=\"top-routes\"></a>\n",
    "## 4. Top Routes Analysis\n",
    "\n",
    "Identify the top 20 origin-destination routes by weight/count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82db683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TOP ROUTES ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "if airport_edges is not None:\n",
    "    # Identify weight column (flight_count or weight)\n",
    "    weight_col = None\n",
    "    for candidate in [\"flight_count\", \"weight\", \"count\", \"n_flights\"]:\n",
    "        if candidate in airport_edges.columns:\n",
    "            weight_col = candidate\n",
    "            break\n",
    "    \n",
    "    # Identify endpoint columns\n",
    "    origin_col = next((c for c in [\"ORIGIN\", \"source\", \"origin\", \"src\"] if c in airport_edges.columns), None)\n",
    "    dest_col = next((c for c in [\"DEST\", \"target\", \"dest\", \"dst\"] if c in airport_edges.columns), None)\n",
    "    \n",
    "    if weight_col and origin_col and dest_col:\n",
    "        print(f\"Using columns: origin={origin_col}, dest={dest_col}, weight={weight_col}\")\n",
    "        \n",
    "        # Get top 20 routes\n",
    "        top_routes = (\n",
    "            airport_edges\n",
    "            .select([origin_col, dest_col, weight_col])\n",
    "            .sort(weight_col, descending=True)\n",
    "            .head(20)\n",
    "            .with_row_index(\"rank\", offset=1)\n",
    "            .to_pandas()\n",
    "        )\n",
    "        \n",
    "        # Create route label\n",
    "        top_routes[\"route\"] = top_routes[origin_col] + \" â†’ \" + top_routes[dest_col]\n",
    "        \n",
    "        print(\"\\nTOP 20 ROUTES BY TRAFFIC:\")\n",
    "        display(top_routes)\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        bars = ax.barh(range(len(top_routes)), top_routes[weight_col], color=sns.color_palette(\"Blues_r\", len(top_routes)))\n",
    "        ax.set_yticks(range(len(top_routes)))\n",
    "        ax.set_yticklabels(top_routes[\"route\"])\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel(f\"{weight_col.replace('_', ' ').title()}\")\n",
    "        ax.set_title(\"Top 20 Airport Routes by Traffic Volume\")\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, val in zip(bars, top_routes[weight_col]):\n",
    "            ax.text(bar.get_width() + 50, bar.get_y() + bar.get_height()/2, \n",
    "                    f\"{val:,.0f}\", va=\"center\", fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(FIGURES_REPORT_DIR / f\"{NOTEBOOK_ID}_top_routes_top20.png\", dpi=150)\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        append_warning(f\"Could not identify required columns in airport_edges\")\n",
    "        top_routes = None\n",
    "else:\n",
    "    top_routes = None\n",
    "    print(\"Not available: airport_edges missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be72492",
   "metadata": {},
   "source": [
    "<a id=\"degree-dist\"></a>\n",
    "## 5. Degree/Strength Distribution\n",
    "\n",
    "Compute and visualize degree/strength proxy distributions to check for hub dominance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f110a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DEGREE/STRENGTH DISTRIBUTION\n",
    "# ============================================================================\n",
    "\n",
    "if airport_edges is not None and origin_col and dest_col:\n",
    "    # Compute out-degree (number of destinations per origin)\n",
    "    out_degree = (\n",
    "        airport_edges\n",
    "        .group_by(origin_col)\n",
    "        .agg(pl.count().alias(\"out_degree\"))\n",
    "        .sort(\"out_degree\", descending=True)\n",
    "    )\n",
    "    \n",
    "    # Compute out-strength (total weight per origin)\n",
    "    if weight_col:\n",
    "        out_strength = (\n",
    "            airport_edges\n",
    "            .group_by(origin_col)\n",
    "            .agg(pl.col(weight_col).sum().alias(\"out_strength\"))\n",
    "            .sort(\"out_strength\", descending=True)\n",
    "        )\n",
    "    \n",
    "    # Plot distributions\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Out-degree distribution\n",
    "    ax1 = axes[0]\n",
    "    degree_vals = out_degree[\"out_degree\"].to_numpy()\n",
    "    ax1.hist(degree_vals, bins=50, edgecolor=\"white\", alpha=0.8)\n",
    "    ax1.set_xlabel(\"Out-Degree (number of destinations)\")\n",
    "    ax1.set_ylabel(\"Frequency\")\n",
    "    ax1.set_title(\"Airport Out-Degree Distribution\")\n",
    "    ax1.axvline(degree_vals.mean(), color=\"red\", linestyle=\"--\", label=f\"Mean: {degree_vals.mean():.1f}\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Out-strength distribution (log scale)\n",
    "    if weight_col:\n",
    "        ax2 = axes[1]\n",
    "        strength_vals = out_strength[\"out_strength\"].to_numpy()\n",
    "        ax2.hist(strength_vals, bins=50, edgecolor=\"white\", alpha=0.8, log=True)\n",
    "        ax2.set_xlabel(f\"Out-Strength ({weight_col})\")\n",
    "        ax2.set_ylabel(\"Frequency (log scale)\")\n",
    "        ax2.set_title(\"Airport Out-Strength Distribution\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_REPORT_DIR / f\"{NOTEBOOK_ID}_degree_strength_proxy_distribution.png\", dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary stats\n",
    "    print(\"\\nDEGREE DISTRIBUTION SUMMARY:\")\n",
    "    print(f\"  Min out-degree: {degree_vals.min()}\")\n",
    "    print(f\"  Max out-degree: {degree_vals.max()}\")\n",
    "    print(f\"  Mean out-degree: {degree_vals.mean():.2f}\")\n",
    "    print(f\"  Median out-degree: {pd.Series(degree_vals).median():.0f}\")\n",
    "else:\n",
    "    print(\"Not available: cannot compute degree distribution without airport_edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20932c3",
   "metadata": {},
   "source": [
    "<a id=\"integrity\"></a>\n",
    "## 6. Integrity Checks\n",
    "\n",
    "Perform basic sanity checks on the network data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INTEGRITY CHECKS\n",
    "# ============================================================================\n",
    "\n",
    "integrity_results = []\n",
    "\n",
    "if airport_edges is not None:\n",
    "    n_edges = len(airport_edges)\n",
    "    \n",
    "    # Check for self-loops\n",
    "    if origin_col and dest_col:\n",
    "        n_self_loops = airport_edges.filter(pl.col(origin_col) == pl.col(dest_col)).height\n",
    "        self_loop_rate = n_self_loops / n_edges if n_edges > 0 else 0\n",
    "        integrity_results.append({\"check\": \"Self-loops\", \"count\": n_self_loops, \"rate\": f\"{self_loop_rate:.4%}\"})\n",
    "    \n",
    "    # Check for duplicate edges\n",
    "    if origin_col and dest_col:\n",
    "        n_unique = airport_edges.select([origin_col, dest_col]).unique().height\n",
    "        n_duplicates = n_edges - n_unique\n",
    "        dup_rate = n_duplicates / n_edges if n_edges > 0 else 0\n",
    "        integrity_results.append({\"check\": \"Duplicate edges\", \"count\": n_duplicates, \"rate\": f\"{dup_rate:.4%}\"})\n",
    "    \n",
    "    # Check for missing endpoints\n",
    "    if origin_col:\n",
    "        n_missing_origin = airport_edges.filter(pl.col(origin_col).is_null()).height\n",
    "        integrity_results.append({\"check\": \"Missing origin\", \"count\": n_missing_origin, \"rate\": f\"{n_missing_origin/n_edges:.4%}\"})\n",
    "    if dest_col:\n",
    "        n_missing_dest = airport_edges.filter(pl.col(dest_col).is_null()).height\n",
    "        integrity_results.append({\"check\": \"Missing dest\", \"count\": n_missing_dest, \"rate\": f\"{n_missing_dest/n_edges:.4%}\"})\n",
    "    \n",
    "    # Check weight non-negativity\n",
    "    if weight_col:\n",
    "        n_negative = airport_edges.filter(pl.col(weight_col) < 0).height\n",
    "        integrity_results.append({\"check\": \"Negative weights\", \"count\": n_negative, \"rate\": f\"{n_negative/n_edges:.4%}\"})\n",
    "\n",
    "integrity_df = pd.DataFrame(integrity_results)\n",
    "print(\"\\nINTEGRITY CHECK RESULTS:\")\n",
    "display(integrity_df)\n",
    "\n",
    "# Flag any issues\n",
    "issues = integrity_df[integrity_df[\"count\"] > 0]\n",
    "if len(issues) > 0:\n",
    "    for _, row in issues.iterrows():\n",
    "        if row[\"count\"] > 0 and row[\"check\"] not in [\"Self-loops\"]:\n",
    "            append_warning(f\"Integrity issue: {row['check']} = {row['count']} ({row['rate']})\")\n",
    "else:\n",
    "    print(\"\\nâœ… All integrity checks passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e90265",
   "metadata": {},
   "source": [
    "<a id=\"interpretation\"></a>\n",
    "## 7. Interpretation\n",
    "\n",
    "### Key Findings (Evidence-Grounded)\n",
    "\n",
    "*(Populated after running cells above)*\n",
    "\n",
    "### Mechanistic Explanation\n",
    "\n",
    "- **Hub dominance**: Heavy-tailed degree/strength distributions indicate presence of major hubs\n",
    "- **Trunk corridors**: Top routes represent high-traffic corridors between major metro areas\n",
    "- **Hub-and-spoke pattern**: High max-degree airports serve as connection points\n",
    "\n",
    "### Evidence Links\n",
    "- Table: `results/tables/report/nb02_top_routes_top20.csv`\n",
    "- Figure: `results/figures/report/nb02_top_routes_top20.png`\n",
    "- Figure: `results/figures/report/nb02_degree_strength_proxy_distribution.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd3067",
   "metadata": {},
   "source": [
    "<a id=\"write-outputs\"></a>\n",
    "## 8. Write Report Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# WRITE REPORT OUTPUTS\n",
    "# ============================================================================\n",
    "\n",
    "# Write network inventory\n",
    "inventory_path = TABLES_REPORT_DIR / f\"{NOTEBOOK_ID}_network_inventory.csv\"\n",
    "inventory_df.to_csv(inventory_path, index=False)\n",
    "print(f\"âœ… Wrote: {inventory_path}\")\n",
    "\n",
    "# Write top routes\n",
    "if top_routes is not None:\n",
    "    routes_path = TABLES_REPORT_DIR / f\"{NOTEBOOK_ID}_top_routes_top20.csv\"\n",
    "    top_routes.to_csv(routes_path, index=False)\n",
    "    print(f\"âœ… Wrote: {routes_path}\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ All {NOTEBOOK_ID} outputs written.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280392a3",
   "metadata": {},
   "source": [
    "<a id=\"reproducibility\"></a>\n",
    "## 9. Reproducibility Notes\n",
    "\n",
    "### Input Files Consumed\n",
    "- `results/networks/airport_nodes.parquet`\n",
    "- `results/networks/airport_edges.parquet`\n",
    "- `results/networks/flight_nodes.parquet`\n",
    "- `results/networks/flight_edges.parquet`\n",
    "- `results/networks/multilayer_edges.parquet`\n",
    "\n",
    "### Assumptions Made\n",
    "1. Edge tables have identifiable source/target columns\n",
    "2. Weight columns represent flight counts or traffic volume\n",
    "3. Airport codes are 3-letter IATA identifiers\n",
    "\n",
    "### Sorting/Ordering\n",
    "- Top routes sorted by weight descending, then by origin ascending (tie-breaking)\n",
    "\n",
    "### Outputs Generated\n",
    "| Artifact | Path |\n",
    "|----------|------|\n",
    "| Network Inventory | `results/tables/report/nb02_network_inventory.csv` |\n",
    "| Top Routes Table | `results/tables/report/nb02_top_routes_top20.csv` |\n",
    "| Top Routes Figure | `results/figures/report/nb02_top_routes_top20.png` |\n",
    "| Degree Distribution | `results/figures/report/nb02_degree_strength_proxy_distribution.png` |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
